{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af721fff-cbba-400e-8285-0bd6776e3a37",
   "metadata": {},
   "source": [
    "# Language Translation\n",
    "\n",
    "Model: (298MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ededa13e-5f71-451e-a770-e9e4c0599ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to install the following packages for this model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pip install transformers sentencepiece protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bc2e90-ba3f-405a-abe8-9b35d7a256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate_text(text, src_lang, tgt_lang):\n",
    "    # First specify the name of the model\n",
    "    model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'\n",
    "    \n",
    "    # Load the pretrained model\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Create a text tokenizer\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt')\n",
    "    \n",
    "    # Run tokens through the model and get the output tokens\n",
    "    outputs = model.generate(inputs, max_length=128, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Translate output tokens to text\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e8f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "german_text = \"Sehr geehrte Damen und Herren, willkommen zu unserer Konferenz zu einem der spannensten Themen dieser Tage: die künstliche Intelligenz. Erfahren Sie, welche Modelle es gibt und wie sie diese in Ihrem Unternehmen einsetzen können.\"\n",
    "english_text = \"In today's program, we would like to recommend you multiple presentations abouts the application of artificial intelligence. This will take place after this workshop.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862769b6-a26a-4aa1-8ae0-3425ca92a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Sehr geehrte Damen und Herren, willkommen zu unserer Konferenz zu einem der spannensten Themen dieser Tage: die künstliche Intelligenz. Erfahren Sie, welche Modelle es gibt und wie sie diese in Ihrem Unternehen einsetzen können.\n",
      "Translated text: Ladies and gentlemen, welcome to our conference on one of the most exciting topics of these days: artificial intelligence. Learn which models are available and how they can be used in your company.\n"
     ]
    }
   ],
   "source": [
    "# Translate from German to English\n",
    "translated_german_to_english = translate_text(german_text, 'de', 'en')\n",
    "print(f\"Original text: {german_text}\\n\\nTranslated text: {translated_german_to_english}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4224a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7165d297650a46df97b992d858bc17df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646bdc5d952644b0aa3df4487e4ebbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc801c70f34479ea026a7076d35d174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51034b7c5c84b80a436677203eedbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a785fba0c9469d93371209e85f6be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd100cbab0e6450fbc9921499e4edb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b389431cbbd04288945f4c09b0ebd983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: In today's program, we would like to recommend you a presentation on artificial intelligence. This will take place at 4 pm in the large lecture hall.\n",
      "\n",
      "Translated text: Im heutigen Programm empfehlen wir Ihnen eine Präsentation über künstliche Intelligenz. Dies findet um 16.00 Uhr im großen Hörsaal statt.\n"
     ]
    }
   ],
   "source": [
    "# Translate from English to German\n",
    "translated_english_to_german = translate_text(english_text, 'en', 'de')\n",
    "print(f\"Original text: {english_text}\\n\\nTranslated text: {translated_english_to_german}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
